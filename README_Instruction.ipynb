{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eeb251a",
   "metadata": {},
   "source": [
    "# Manual Instruction\n",
    "This Jupyter notebook provides a detailed explanation of the code of my research project “**Event Detection-based Method for Online Signal Synchronization in Time Series**\".  \n",
    "\n",
    "Hao Zhu, MSc at ETH\n",
    "26.09.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3419cc",
   "metadata": {},
   "source": [
    "## Dataset Insight\n",
    "1. In this recording, there are syncing event at the beginning and ending. They are clear at Acc signals and also (especially) at Sensomat signals. However, from my observation, the starting syncing event may not successfully capture because some sensors are not activated successfully when recording began. Hence, using the ending syncing event signals are clearer and better than starting syncing event signals.  \n",
    "2. Some sensors recording csv files includes multiple days. We have to exclude those unnecessary days. Therefore, we need the *Sensei-V2 - Modified-Labels.xlsx* file for help. We can use the frame number of the recordings as they are accurately reflect events. (See utils/unzipper.py section below)\n",
    "3. Raw data inevitably has missing values.\n",
    "4. From my observation, sensomat data provide the most accurate relection of syncing event and complete datapoints. So I set sensomat data as the reference time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78464812",
   "metadata": {},
   "source": [
    "## Code Structure Overview\n",
    "The repository include 3 folders: config, src, and utils\n",
    "```\n",
    "DATA_SYNC/  \n",
    "|  \n",
    "|--config/  \n",
    "|  |  \n",
    "|  |--csv_config.yaml  \n",
    "|  \n",
    "|--utils/  \n",
    "|  |  \n",
    "|  |--data_augmentation_utils.py  \n",
    "|  |  \n",
    "|  |--files_utils.py  \n",
    "|  |  \n",
    "|  |--plotting_utils.py  \n",
    "|  |  \n",
    "|  |--stream_sync.py   \n",
    "|  |  \n",
    "|  |--time_utils.py  \n",
    "|  |  \n",
    "|  |--unzipper.py  \n",
    "|\n",
    "|--src/  \n",
    "|  |  \n",
    "|  |--detectors/  \n",
    "|  |  |  \n",
    "|  |  |--detector_zoo.py  \n",
    "|  |  |  \n",
    "|  |  |--event_detector.py  \n",
    "|  |  \n",
    "|  |--evaluation/  \n",
    "|  |  |  \n",
    "|  |  |--evaluation.py\n",
    "|  |\n",
    "|  |--DataReceiver.py\n",
    "|  |\n",
    "|  |--data_benchmark.py\n",
    "|  |\n",
    "|  |--signal_sync.py\n",
    " \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63194de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pytz\n",
    "import threading\n",
    "\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from collections import deque, defaultdict\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "\n",
    "MYTZ = \"Europe/Zurich\"\n",
    "tzinfo = pytz.timezone(MYTZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6bdc44",
   "metadata": {},
   "source": [
    "## Utils\n",
    "In the following parts, I will explain the implementation of the logic of each python script under Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275864d3",
   "metadata": {},
   "source": [
    "### data_augmentation_utils.py  \n",
    "This script provides some data augmentation methods for time series data.  \n",
    "\n",
    "The notable method is *apply_time_drift*, which simulates the clock shift across time. It applied a drift to the timestamps in a DataFrame over specified intervals.  \n",
    "\n",
    "Parameters:  \n",
    "df (pd.DataFrame): target DataFrame with a 'time' column to be drifted.  \n",
    "drift_interval_seconds (int): Interval at which to apply the drift in seconds.  \n",
    "drift_amount_seconds (float): Amount of drift to apply at each interval in seconds.  \n",
    "\n",
    "Just focus on the **for loop**, The function iterate the each timestamp of the target df. When the time different current timestamp and the previous timestamp is larger than *specific interval (drift_interval_seconds)*, we add *specific time (drift_amount_seconds)* to all subsequent timestamps starting from index i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_time_drift(df, drift_interval_seconds, drift_amount_seconds):\n",
    "    \"\"\"\n",
    "    Apply time drift to the timestamps in the dataframe at regular intervals.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame with a 'time' column.\n",
    "    drift_interval_seconds (int): Interval at which to apply the drift in seconds.\n",
    "    drift_amount_seconds (float): Amount of drift to apply at each interval in seconds.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with drifted timestamps.\n",
    "    \"\"\"\n",
    "    df_augmented = df.copy()\n",
    "    drifted_timestamps = df_augmented['time'].copy()\n",
    "    \n",
    "    start_time = drifted_timestamps.iloc[0]\n",
    "    \n",
    "    for i in range(1, len(drifted_timestamps)):\n",
    "        if (drifted_timestamps.iloc[i] - start_time).total_seconds() >= drift_interval_seconds:\n",
    "            drifted_timestamps.iloc[i:] += pd.Timedelta(seconds=drift_amount_seconds)\n",
    "            start_time = drifted_timestamps.iloc[i]\n",
    "    \n",
    "    df_augmented['time'] = drifted_timestamps\n",
    "    return df_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accda331",
   "metadata": {},
   "source": [
    "### files_utils.py\n",
    "This script is a helper scirpt to unzip all the files from raw zip files. Since we don't know the exact layers of each folders, we implemented it based on a *recursion* manner.  \n",
    "\n",
    "The function **unzipper** is the major functions to run. Given the root directory, it will unzip all .gz file resursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_gz_file(filepath):\n",
    "    # Check if the file has a .gz extension\n",
    "    return filepath.endswith('.gz')\n",
    "\n",
    "\n",
    "def unzip_gz_file(filepath, output_dir=None):\n",
    "    if not is_gz_file(filepath):\n",
    "        return ''\n",
    "    \n",
    "    # Define the output file path\n",
    "    if output_dir is None:\n",
    "        output_filepath = os.path.splitext(filepath)[0]  # Remove the .gz extension\n",
    "    else:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        output_filepath = os.path.join(output_dir, os.path.basename(os.path.splitext(filepath)[0]))\n",
    "\n",
    "    # Unzip the .gz file\n",
    "    with gzip.open(filepath, 'rb') as f_in:\n",
    "        with open(output_filepath, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "    return output_filepath\n",
    "\n",
    "\n",
    "def unzipper(path):\n",
    "    \"\"\"\n",
    "    recursively unzip all the csv files in  subfolders under the directory\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        \n",
    "        output_file = unzip_gz_file(path)\n",
    "        return\n",
    "    \n",
    "    for entry in os.listdir(path):\n",
    "        new_path = os.path.join(path, entry)\n",
    "        unzipper(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988a3e2",
   "metadata": {},
   "source": [
    "### plotting_utils.py\n",
    "This is a helper function for plotting colors. There is only one function which works like a color palette so we don't need to worry how to assign colors when the number of sensors are unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f5512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/a/25628397\n",
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba66ef",
   "metadata": {},
   "source": [
    "### time_utils.py\n",
    "This files provide some helper conversion from between unix epoch time <-> datetime and frame number to exact time.  \n",
    "*frame2sec*: Because we can locate the precise frame number of the start and the end of recording (provided by a excel file), we can use this to infer to precise time in seconds. FS = $\\frac{\\text{total frames}}{\\text{total seconds}}$  \n",
    "\n",
    "*sec2datetime*: start_time is a datetime object, adding the timedelta can result a new datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the frame rate to seconds\n",
    "def frame2sec(frame_cur, frame_begin, FS):\n",
    "    return (frame_cur - frame_begin) / FS\n",
    "\n",
    "# convert seconds to datetime object\n",
    "def sec2datetime(second, start_time):\n",
    "    return start_time + timedelta(seconds=second)\n",
    "\n",
    "\n",
    "# convert the datetime object to unix epoch time\n",
    "def time2UnixEpochTime(datetime_obj):\n",
    "    # Define the format\n",
    "    datetime_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "    unix_timestamp = int(datetime_obj.timestamp())\n",
    "    \n",
    "    return unix_timestamp\n",
    "\n",
    "def unixEpochTime2time(u_time):\n",
    "    return datetime.fromtimestamp(u_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f10a54c",
   "metadata": {},
   "source": [
    "An example of how to use it to find the exact starting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_guide_xlsx = 'PATH_TO_XLSX'\n",
    "user_id = 'sensei-223'\n",
    "YEAR, MONTH, DAY = 2022, 11, 14\n",
    "user_event = label_guide_xlsx[label_guide_xlsx['User'] == user_id].iloc[0]\n",
    "\n",
    "start_frame = user_event['first_frame_of_second_START']\n",
    "start_time  = user_event['frame_laptop_time_START']\n",
    "end_frame   = user_event['first_frame_of_second_END']\n",
    "end_time    = user_event['frame_laptop_time_END']\n",
    "\n",
    "sync_frame_start = user_event['VideoFrame_Touchpad_START_1']\n",
    "sync_frame_end = user_event['VideoFrame_Touchpad_END_3']\n",
    "\n",
    "rec_date  = datetime(YEAR, MONTH, DAY)\n",
    "start_time_comb = datetime.combine(rec_date, start_time)\n",
    "end_time_comb   = datetime.combine(rec_date, end_time)\n",
    "\n",
    "duration_seconds = (end_time_comb - start_time_comb).total_seconds()\n",
    "total_frames = end_frame - start_frame\n",
    "\n",
    "FS = total_frames / duration_seconds\n",
    "\n",
    "accurate_sec_sync_start = frame2sec(sync_frame_start, start_frame, FS)\n",
    "accurate_datetime_sync_start = sec2datetime(accurate_sec_sync_start - 5, start_time_comb)\n",
    "unix_start = int(accurate_datetime_sync_start.timestamp())\n",
    "\n",
    "accurate_sec_sync_end = frame2sec(sync_frame_end, start_frame, FS)\n",
    "accurate_datetime_sync_end = sec2datetime(accurate_sec_sync_end + 15, start_time_comb)\n",
    "unix_end = int(accurate_datetime_sync_end.timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c3398f",
   "metadata": {},
   "source": [
    "### unzipper.py\n",
    "This file helps to unzip all the file from root directory using the function *files_utils/unzipper* and extract the exact starting and ending unix epoch time for each user recordings by calling the example above.  \n",
    "\n",
    "For every recording, the idea is as followed:  \n",
    "1) Read the *Sensei-V2 - Modified-Labels.xlsx* file for knowing the rough labels for starting/ending of the recordings and also the events. Some important labels are:  \n",
    "    • *first_frame_of_second_START* AND *frame_laptop_time_START*: *first_frame_of_second_START* (frame number of starting the recording) is accurately aligns with *frame_laptop_time_START* (time of starting the recording)  \n",
    "    • *first_frame_of_second_END* AND *frame_laptop_time_END*: *first_frame_of_second_END* (frame number of ending the recording) is accurately aligns with *frame_laptop_time_START* (time of ending the recording).  \n",
    "    • *VideoFrame_Touchpad_START_1* AND *VideoFrame_Touchpad_END_3*: These two labels reflect the exact frame number of starting syncing event and ending syncing event. Frame number is accurate but the time, *Timestamp_Touchpad_START_1* is NOT. \n",
    "    Because the time and frame are accurately aligned, when can use this to calculate FS: FS = $\\frac{\\text{total frames}}{\\text{total seconds}}$. Hence, the code is like:  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be56b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_frame = user_event['first_frame_of_second_START']\n",
    "start_time  = user_event['frame_laptop_time_START']\n",
    "end_frame   = user_event['first_frame_of_second_END']\n",
    "end_time    = user_event['frame_laptop_time_END']\n",
    "\n",
    "\n",
    "rec_date  = datetime(YEAR, MONTH, DAY)\n",
    "start_time_comb = datetime.combine(rec_date, start_time)\n",
    "end_time_comb   = datetime.combine(rec_date, end_time)\n",
    "\n",
    "duration_seconds = (end_time_comb - start_time_comb).total_seconds()\n",
    "total_frames = end_frame - start_frame\n",
    "\n",
    "FS = total_frames / duration_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0846f831",
   "metadata": {},
   "source": [
    "2) The labels of timestamps of syncing event are not accurate, but the frame number are. Therefore, we can use the label *VideoFrame_Touchpad_START_1* and *VideoFrame_Touchpad_END_3* to know the frame, and use the *frame_laptop_time_START* and the calculated FS to calculate the exact starting time.  \n",
    "   • line 4: get number of seconds between recording start frame and sync event start frame.  \n",
    "   • line 5: recroding start time adds the seconds calculated from line 4 and convert to datetime object.  \n",
    "   • line 6: convert datetime object to unix epoch time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_frame_start = user_event['VideoFrame_Touchpad_START_1']\n",
    "sync_frame_end = user_event['VideoFrame_Touchpad_END_3']\n",
    "\n",
    "accurate_sec_sync_start = frame2sec(sync_frame_start, start_frame, FS)\n",
    "accurate_datetime_sync_start = sec2datetime(accurate_sec_sync_start - 5, start_time_comb)\n",
    "unix_start = int(accurate_datetime_sync_start.timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dc86b0",
   "metadata": {},
   "source": [
    "## src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde28cc",
   "metadata": {},
   "source": [
    "### detectors/detector_zoo.py\n",
    "This script provide a bunch of models for Anomaly/Event Detection. The models are all from [scikit-learn](https://scikit-learn.org/stable/).   \n",
    "• IsolationForest  \n",
    "• OneClassSVM  \n",
    "• **LocalOutlierFactor**  (current best method I tested)  \n",
    "• SGDOneClassSVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98742476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import SGDOneClassSVM\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from nixtla import NixtlaClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(sensor_config):\n",
    "    model_name = sensor_config['model_name']\n",
    "    if model_name == 'IsolationForest':\n",
    "        model = IsolationForest(contamination=0.0001, random_state=42)\n",
    "    elif model_name == 'OneClassSVM':\n",
    "        model = svm.OneClassSVM(nu=0.0001, kernel=\"rbf\", gamma=0.1)\n",
    "    elif model_name == 'LocalOutlierFactor':\n",
    "        model = LocalOutlierFactor(n_neighbors=35, contamination=0.05)\n",
    "    elif model_name == 'SGDOneClassSVM':\n",
    "        model = make_pipeline(\n",
    "            Nystroem(gamma=0.1, random_state=42, n_components=100),\n",
    "            SGDOneClassSVM(\n",
    "                nu=0.01,\n",
    "                shuffle=True,\n",
    "                fit_intercept=True,\n",
    "                random_state=42,\n",
    "                tol=1e-6,\n",
    "            )\n",
    "        )\n",
    "    elif model_name == 'TimeGPT':\n",
    "        nixtla_client = NixtlaClient(\n",
    "            # defaults to os.environ.get(\"NIXTLA_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        \n",
    "        return nixtla_client\n",
    "    else: return NotImplementedError\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef71676",
   "metadata": {},
   "source": [
    "### detectors/event_detector.py \n",
    "This script leverages the chosen model from last step to `fit_predict` input features to calculate the anomaly score (if an event is detected).  \n",
    "\n",
    "The input `window` is the fixed size deque of lastest data. Since `time` and `timestamp` is not relevant for event detection, we drop these two columns first. We can simly call `fit_predict` to get if an event is detected since this is a common functino across all sklearn model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275af982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detector(model_name : str):\n",
    "    if model_name == \"TimeGPT\":\n",
    "        return detector_timeGPT\n",
    "    else: return detector_sk\n",
    "\n",
    "def detector_sk(window, model):\n",
    "    \"\"\"\n",
    "    detector for using sklearn model\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(list(window))\n",
    "    features = features.drop(columns=['time', 'timestamp'], errors='ignore')\n",
    "    anomaly_scores = model.fit_predict(features)\n",
    "    anomaly_scores = (anomaly_scores == -1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60701c86",
   "metadata": {},
   "source": [
    "### evaluation/metric.py\n",
    "The timestamp is manually shifted first and synchronized. The evaluation in this script is based on the difference between the synchronized timestamp and the original timestamp.  \n",
    "\n",
    "There are 2 metrics I implemented: **RMSE** and **MAE**.  \n",
    "• $\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$  \n",
    "• $\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$  \n",
    "$y_i$ is the ground truth timestamp for $i$th data point; $\\hat{y}_i$ is the synchronized timestamp for $i$th data point\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(corrected_df, gt_df):\n",
    "    corrected_time = corrected_df['time'].reset_index(drop=True)\n",
    "    gt_time = gt_df['time'].reset_index(drop=True)\n",
    "    \n",
    "    time_error = (corrected_time - gt_time).dt.total_seconds()\n",
    "    rmse = np.sqrt((time_error ** 2).mean())\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def MAE(corrected_df, gt_df):\n",
    "    corrected_time = corrected_df['time'].reset_index(drop=True)\n",
    "    gt_time = gt_df['time'].reset_index(drop=True)\n",
    "    \n",
    "    time_error = (corrected_time - gt_time).dt.total_seconds()\n",
    "    mae = time_error.abs().mean()\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6a5c1",
   "metadata": {},
   "source": [
    "### evaluation/evaluation.py\n",
    "This function calls the evaluation metric (RMSE & MAE).  \n",
    "\n",
    "Input parameters:\n",
    "• *updated_dfs*: The synchronized dataframe with synchronized timestamp  \n",
    "• *gt_dfs*: The ground truth dataframe with groud truth timestamp  \n",
    "\n",
    "However, since the *updated_dfs* is reading from threading, which is not a datetime object, we have to make extra steps that force casting the type of `time` to a datetime object. Check line 5 & 6 in below cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(updated_dfs, gt_dfs):\n",
    "    for sensor_name in gt_dfs.keys():\n",
    "        print(f\"sensor_name: {sensor_name}\")\n",
    "\n",
    "        updated_dfs[sensor_name]['time'] = pd.to_datetime(updated_dfs[sensor_name]['time'], errors='coerce')\n",
    "        updated_dfs[sensor_name]['time'] = updated_dfs[sensor_name]['time'].dt.tz_convert(tzinfo)\n",
    "        rmse = RMSE(updated_dfs[sensor_name], gt_dfs[sensor_name])\n",
    "        mae = MAE(updated_dfs[sensor_name], gt_dfs[sensor_name])\n",
    "\n",
    "        print(f\"RMSE of Sensor {sensor_name}: {rmse}\")\n",
    "        print(f\"MAE of Sensor {sensor_name}: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24112b5",
   "metadata": {},
   "source": [
    "### data_benchmark.py\n",
    "This scripts aims to benchmark the recordings and reset all the timestamp from 1970.01.01 so that the data is anonymous.\n",
    "\n",
    "The script hold a similar structure and logic as in `utils/unzipper.py` above as it also requires to find the exact starting/ending timestamp. But here are some extra steps to handle.\n",
    "\n",
    "1. Find the reference timestamp (sensomat data). Find the 0th index timestamp point as the reference starting time (line 6).    \n",
    "```bash\n",
    "1 gt_mat_rec = gt_mat_rec.sort_values(by='time')\n",
    "2 gt_mat_rec_idx = gt_mat_rec[(gt_mat_rec['time'] >= unix_start) & (gt_mat_rec['time'] <= unix_end)].index\n",
    "3 gt_mat_rec = gt_mat_rec.loc[gt_mat_rec_idx]\n",
    "4 \n",
    "5 gt_senso_time = gt_mat_rec['time'].to_numpy()\n",
    "6 gt_starting_time = gt_senso_time[0]\n",
    "```  \n",
    "\n",
    "2. Iterate all the csv files (even include reference sensor recording) in this recording. We will subtract the starting time by the `gt_starting_time` to reset the timestamp (line 5).  \n",
    "```bash\n",
    "1 csv_df = csv_df.sort_values(by='time')\n",
    "2 csv_df_idx = csv_df[(csv_df['time'] >= unix_start) & (csv_df['time'] <= unix_end)].index\n",
    "3 csv_df = csv_df.loc[csv_df_idx]\n",
    "4 \n",
    "5 csv_df['time'] = csv_df['time'] - gt_starting_time\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb79f5",
   "metadata": {},
   "source": [
    "### signal_sync.py\n",
    "This function is to project the input shifted dataframe timestamp to reference timestamp. The main idea is to normalize the shifted dataframe to 0~1 and project the result from starting time.   \n",
    "\n",
    "Once an event is detected from any sensors (except the reference sensor), run this function and synchronized the time to all sensors (except the reference sensor).  \n",
    "\n",
    "Signal Sync applies on a certain time range. Time range is extracted in bewtween the previous detected event time and current detected event time.   \n",
    "\n",
    "Input param  \n",
    "• *ref_name*: Name of reference sensor name\n",
    "• *dfs*: The dataframe that stores the loading data  \n",
    "• *prev_frame*: The prev_frame that detected an event  \n",
    "• *frame*: The current frame that detected an event   \n",
    "\n",
    "The synchrnization runs between two frames.\n",
    "\n",
    "```bash\n",
    "1 df_normalized_times = (\n",
    "2         df_frame['time'].apply(lambda x: x.timestamp() if pd.notnull(x) else np.nan) - df_start_timestamp)\n",
    "3       / (df_end_timestamp - df_start_timestamp)\n",
    "4\n",
    "5 aligned_timestamps = ref_start_timestamp + df_normalized_times * (ref_end_timestamp - ref_start_timestamp)\n",
    "```\n",
    "\n",
    "The steps are:\n",
    "\n",
    "1. Normalize the shifted signal from 0 to 1\n",
    "$$ \\text{normalized\\_time} = \\frac{\\text{timestamp} - \\text{start time}}{\\text{end time} - \\text{start time}} $$\n",
    "\n",
    "2. Interpolate the normalized signals by reference time\n",
    "$$ \\text{aligned\\_time} = \\text{ref start time} + (\\text{normalized\\_time} \\times (\\text{ref end time} - \\text{ref start time})) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronization(\n",
    "        ref_name : str, \n",
    "        dfs : dict, \n",
    "        prev_frame : int, \n",
    "        frame : int):\n",
    "    \n",
    "    ref = dfs[ref_name]\n",
    "    ref_frame = ref.iloc[prev_frame : frame + 1]\n",
    "\n",
    "    if ref_frame.empty:\n",
    "        print(\"Reference frame is empty. Skipping synchronization.\")\n",
    "        return dfs, prev_frame\n",
    "\n",
    "    ref_start_time = ref_frame['time'].iloc[0]\n",
    "    ref_end_time = ref_frame['time'].iloc[-1]\n",
    "\n",
    "    ref_start_timestamp = ref_start_time.timestamp()\n",
    "    ref_end_timestamp = ref_end_time.timestamp()\n",
    "\n",
    "    for i, (sensor_name, df) in enumerate(dfs.items()):\n",
    "        if sensor_name == ref_name: continue\n",
    "        df_frame = df.iloc[prev_frame : frame + 1]\n",
    "        if df_frame.empty:\n",
    "            print(f\"DataFrame for {sensor_name} is empty. Skipping synchronization for this sensor.\")\n",
    "            continue\n",
    "\n",
    "        df_start_time = df_frame['time'].iloc[0]\n",
    "        df_end_time = df_frame['time'].iloc[-1]\n",
    "\n",
    "       \n",
    "        df_start_timestamp = df_start_time.timestamp()\n",
    "        df_end_timestamp = df_end_time.timestamp()\n",
    "\n",
    "        # normalize the shifted timestamp to 0~1               \n",
    "        df_normalized_times = (\n",
    "            df_frame['time'].apply(lambda x: x.timestamp() if pd.notnull(x) else np.nan) - df_start_timestamp\n",
    "        ) / (df_end_timestamp - df_start_timestamp)\n",
    "\n",
    "        # Drop NaN values\n",
    "        df_normalized_times = df_normalized_times.dropna()\n",
    "\n",
    "        if len(df_normalized_times) == 0:\n",
    "            print(f\"DataFrame for {sensor_name} after normalization is empty. Skipping synchronization for this sensor.\")\n",
    "            continue\n",
    "\n",
    "        aligned_timestamps = ref_start_timestamp + df_normalized_times * (ref_end_timestamp - ref_start_timestamp)\n",
    "\n",
    "        aligned_times = pd.to_datetime(aligned_timestamps, unit='s')\n",
    "        aligned_times = aligned_times.dt.tz_localize('UTC').dt.tz_convert(tzinfo)\n",
    "\n",
    "        df.loc[prev_frame : frame, 'time'] = aligned_times\n",
    "        df.loc[prev_frame : frame, 'timestamp'] = aligned_timestamps\n",
    "        \n",
    "    prev_frame = frame\n",
    "    return dfs, prev_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b25692",
   "metadata": {},
   "source": [
    "### DataReceiver.py\n",
    "The class captures all the data loading from multi-threading function. \n",
    "\n",
    "####  class members\n",
    "The class members can be divided into two parts: data members and plotting members\n",
    "1. Data members  \n",
    "- self.window_size: dtype: map; window size of each sensor  \n",
    "- self.dataframe: dtype: map; empty *pd.DataFrame* for each sensor  \n",
    "- self.window: dtype: map; empty *deque* with specified window_size for each sensor  \n",
    "- self.anomaly_scores: dtype: map; empty *list* for each sensor  \n",
    "- self.ref_sensor: name of reference sensor, which is \"sensomat\"\n",
    "- self.model: dtype: map; event detection model for each sensor\n",
    "- self.detector: dtype: map; the corresponding detector for each sensor in respond to the model\n",
    "- self.columns_map: dtype: map; the columns that liek to keep for each sensor\n",
    "\n",
    "2. plotting members\n",
    "- self.lines_map: the map store the corresponding line of each sensor and anomaly score\n",
    "- self.prev_timeframe: previous timestamp\n",
    "- self.axes: axis that stores for each subplot\n",
    "- self.fig: plt.fig of current figure\n",
    "- self.ani: object of FuncAnimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReceiver:\n",
    "    def __init__(self, \n",
    "                 sensors_config: Dict[str, Dict[str, Any]],\n",
    "                 plotting: bool,\n",
    "                 df_map: Dict[str, Any]):\n",
    "        self.sensors_config = sensors_config\n",
    "        self.sensors = list(sensors_config.keys())\n",
    "        self.df_map = df_map\n",
    "\n",
    "        self.window_size = {sensor: self.sensors_config[sensor]['window_size'] for sensor in self.sensors}\n",
    "        self.dataframe = {sensor: pd.DataFrame(columns=self.sensors_config[sensor]['columns']) for sensor in self.sensors}\n",
    "        self.window = {sensor: deque(maxlen=self.sensors_config[sensor]['window_size']) for sensor in self.sensors}\n",
    "        self.anomaly_scores = {sensor: [] for sensor in self.sensors}\n",
    "        self.ref_sensor = 'mat'\n",
    "        self.model = {sensor: get_model(self.sensors_config[sensor]) for sensor in self.sensors}\n",
    "        self.detector = {sensor: get_detector(self.sensors_config[sensor]['model_name']) for sensor in self.sensors}\n",
    "        self.columns_map = {sensor: self.sensors_config[sensor]['columns'] for sensor in self.sensors}\n",
    "        self.lock = threading.Lock()  # Ensure thread-safe operations\n",
    "\n",
    "        # Plotting members\n",
    "        self.lines_map = defaultdict(list)\n",
    "        self.prev_timeframe = 0\n",
    "        self.axes = None\n",
    "        self.fig = None\n",
    "        self.ani = None\n",
    "        self.all_data_streams_completed = threading.Event() ## ADD\n",
    "        self.animation_running = True\n",
    "        if plotting:\n",
    "            self.init_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02ca1c",
   "metadata": {},
   "source": [
    "#### DataReceiver.init_plot()\n",
    "This function initialize plotting. It sets up the figure to plot the data. Evey sensor has two subplots (*so the number of subplot is len(sensors) * 2*). The even plot plot (0-indexed) always plot the anomaly score and odd plot plot (0-indexed) the data, e.g. accX, accY, accZ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15501895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_plot(self):\n",
    "    fig, axes = plt.subplots(len(self.sensors) * 2, 1, figsize=(12, 10), sharex=False)\n",
    "    color_map = plt.get_cmap('tab10')\n",
    "\n",
    "    for i, (sensor_name, columns) in enumerate(self.columns_map.items()):\n",
    "        line, = axes[2 * i].plot([], [], label=f'Anomaly Score of {sensor_name}', color='red', marker='.')\n",
    "        self.lines_map[sensor_name].append((line))\n",
    "        axes[2 * i].set_ylabel('Anomaly Score')\n",
    "        axes[2 * i].legend()\n",
    "        axes[2 * i].grid(True)\n",
    "\n",
    "        for j, c in enumerate(columns[2:]):\n",
    "            color_idx = (i * len(columns) + j) % color_map.N\n",
    "            line_temp, = axes[2 * i + 1].plot([], [], label=c, color=color_map(color_idx), marker='.')\n",
    "            self.lines_map[sensor_name].append((line_temp))\n",
    "\n",
    "        axes[2 * i + 1].set_xlabel('Time')\n",
    "        axes[2 * i + 1].set_ylabel(sensor_name)\n",
    "        axes[2 * i + 1].legend()\n",
    "        axes[2 * i + 1].grid(True)\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.3)\n",
    "    plt.suptitle('Live Data Streaming with Time Drift')\n",
    "\n",
    "    self.axes = axes\n",
    "    self.fig = fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3d713",
   "metadata": {},
   "source": [
    "#### DataReceiver.update_data(self, sensor_name: str, sensor_data: pd.DataFrame)\n",
    "Input param\n",
    "- sensor_name: name of the current sensor that loading the data \n",
    "- sensor_data: the latest sensor_data loading  \n",
    "New data needs to concatenate back to the orginal `dataframe` and append to the end of `window`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3801042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(self, sensor_name: str, sensor_data: pd.DataFrame):\n",
    "    with self.lock:\n",
    "        sensor_data = sensor_data.T\n",
    "        sensor_data = sensor_data[[*self.columns_map[sensor_name]]]\n",
    "        self.dataframe[sensor_name] = pd.concat([self.dataframe[sensor_name], sensor_data], ignore_index=True)\n",
    "        self.window[sensor_name].append(sensor_data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf154a1",
   "metadata": {},
   "source": [
    "#### DataReceiver.event_detect(self, sensor_name: str)\n",
    "Input param\n",
    "- sensor_name: name of the current sensor  \n",
    "\n",
    "If the window is greater than the threshold window size of this sensor, then run the `detector` and append latest anomaly score, else no event is detected.  \n",
    "\n",
    "0 in anomaly score is no event detected; 1 means an event is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567695ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_detect(self, sensor_name: str):\n",
    "    with self.lock:\n",
    "        cur_window = self.window[sensor_name]\n",
    "        if len(cur_window) == self.window_size[sensor_name]:\n",
    "            predicted_score = self.detector[sensor_name](cur_window, self.model[sensor_name])\n",
    "            self.anomaly_scores[sensor_name].append(predicted_score[-1])\n",
    "        else:\n",
    "            self.anomaly_scores[sensor_name].append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be3372",
   "metadata": {},
   "source": [
    "#### DataReceiver.update_plot(self, frame)\n",
    "For each sensor, if the `anomaly score` is changed, either from no event to detected event or vice versa. Run the script of `synchronization()`. Then update the plot by only using the lasest certain numbers of values.  \n",
    "\n",
    "If all data has been loaded, then run the `synchronization()` last time and run `evaluation`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b17a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_plot(self, frame):\n",
    "    if not self.animation_running:\n",
    "        return \n",
    "\n",
    "    with self.lock:\n",
    "        for s in self.sensors:\n",
    "            cur_a_score = self.anomaly_scores[s]\n",
    "            # when anomaly score is changed, synchronize the time for all sensor\n",
    "            if len(cur_a_score) >= 2 and cur_a_score[-1] != cur_a_score[-2]:\n",
    "                # TODO: Ensure synchronization is correct\n",
    "                self.dataframe, self.prev_timeframe = synchronization(self.ref_sensor, self.dataframe, self.prev_timeframe, frame)\n",
    "                \n",
    "        for i, (sensor_name, columns) in enumerate(self.columns_map.items()):\n",
    "            if len(self.dataframe[sensor_name]) > 0:  # Ensure there is data\n",
    "                self.lines_map[sensor_name][0].set_data(self.dataframe[sensor_name]['time'][-100:], self.anomaly_scores[sensor_name][-100:])\n",
    "                for j, c in enumerate(columns[2:]):\n",
    "                    self.lines_map[sensor_name][j + 1].set_data(self.dataframe[sensor_name]['time'][-100:], self.dataframe[sensor_name][c][-100:])\n",
    "\n",
    "                if not self.dataframe[sensor_name].empty:\n",
    "                    self.axes[2 * i].set_xlim(self.dataframe[sensor_name]['time'][-100:].min(), self.dataframe[sensor_name]['time'][-100:].max())\n",
    "                    self.axes[2 * i].set_ylim(-1.2, 1.2)\n",
    "\n",
    "                    self.axes[2 * i + 1].set_xlim(self.dataframe[sensor_name]['time'][-100:].min(), self.dataframe[sensor_name]['time'][-100:].max())\n",
    "                    self.axes[2 * i + 1].set_ylim(self.dataframe[sensor_name][[*columns[2:]]][-100:].min().min() - 0.1, self.dataframe[sensor_name][[*columns[2:]]][-100:].max().max() + 0.1)\n",
    "\n",
    "    if self.all_data_streams_completed.is_set():\n",
    "        print(\"All data streams have completed. Stopping animation.\")\n",
    "        self.animation_running = False\n",
    "        for s in self.sensors:\n",
    "            cur_a_score = self.anomaly_scores[s]\n",
    "            # TODO: Ensure synchronization is correct\n",
    "            self.dataframe, self.prev_timeframe = synchronization(self.ref_sensor, self.dataframe, self.prev_timeframe, frame)\n",
    "        run_eval(self.dataframe, self.df_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a5b2ef",
   "metadata": {},
   "source": [
    "## config\n",
    "This folder only includes one file, which structures the config for the DataReceiver class member. Hence, we can very easily add/delete/change the some configurations of sensors.\n",
    "\n",
    "For instance, we can tune window size, model and its corresponding parameter for specific sensor\n",
    "\n",
    "```\n",
    "config/.yaml\n",
    "\n",
    "sensors:\n",
    "  - name: cos\n",
    "    file: /path/to/cos_acc.csv\n",
    "    columns: \n",
    "      - time\n",
    "      - timestamp\n",
    "      - acc_x\n",
    "      - acc_y\n",
    "      - acc_z\n",
    "    model_name: LocalOutlierFactor\n",
    "    parameters:\n",
    "      n_neighbors: 35\n",
    "      contamination: 0.01\n",
    "    window_size: 100\n",
    "  - name: cor\n",
    "    file: /path/to/cos_acc.csv\n",
    "    columns: \n",
    "      - time\n",
    "      - timestamp\n",
    "      - accX\n",
    "      - accY\n",
    "      - accZ\n",
    "    model_name: LocalOutlierFactor\n",
    "    parameters:\n",
    "      n_neighbors: 35\n",
    "      contamination: 0.01\n",
    "    window_size: 100\n",
    "  - name: mat\n",
    "    file: /path/to/mat.csv\n",
    "    columns: \n",
    "      - time\n",
    "      - timestamp\n",
    "      - device1_value4\n",
    "      - device1_value5\n",
    "      - device1_value9\n",
    "    model_name: LocalOutlierFactor\n",
    "    parameters:\n",
    "      n_neighbors: 35\n",
    "      contamination: 0.01\n",
    "    window_size: 100\n",
    "  - name: viva_acc\n",
    "    file: /path/to/viva_hr.csv\n",
    "    columns: \n",
    "      - time\n",
    "      - timestamp\n",
    "      - x\n",
    "      - y\n",
    "      - z\n",
    "    model_name: LocalOutlierFactor\n",
    "    parameters:\n",
    "      n_neighbors: 35\n",
    "      contamination: 0.01\n",
    "    window_size: 100\n",
    "plotting: true\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc8c350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
